# üß† –£—Å—Ç–∞–Ω–æ–≤–∫–∞ AI Transformers –¥–ª—è SolarMail

## Sprint 0.3: ML Models Integration

---

## üìã –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ:
- Python 3.11+
- 4 GB RAM
- 2 GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ:
- Python 3.11+
- 8 GB RAM
- NVIDIA GPU —Å CUDA (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è)
- 5 GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ

---

## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

### –í–∞—Ä–∏–∞–Ω—Ç 1: CPU only (–±–µ–∑ GPU)

```bash
# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º transformers –∏ torch (CPU –≤–µ—Ä—Å–∏—è)
pip install transformers torch sentencepiece --break-system-packages

# –ò–ª–∏ –∏–∑ requirements.txt
pip install -r requirements.txt --break-system-packages
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –° –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GPU (CUDA)

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ torch —Å CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --break-system-packages

# –ó–∞—Ç–µ–º transformers
pip install transformers sentencepiece --break-system-packages
```

---

## üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

–ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∑—è—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:

```python
from ai_parser_transformer import AIParserTransformer

# –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∑—è—Ç—Å—è –∏–∑ Hugging Face Hub
parser = AIParserTransformer()
```

**–ú–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã:**
1. `distilbert-base-uncased-finetuned-sst-2-english` (~260 MB)
   - Sentiment analysis
2. `facebook/bart-large-mnli` (~1.6 GB)
   - Zero-shot classification –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π

**–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä:** ~1.9 GB

### –†—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

```python
from transformers import pipeline

# –ó–∞–≥—Ä—É–∑–∏—Ç—å sentiment model
sentiment = pipeline("sentiment-analysis", 
                     model="distilbert-base-uncased-finetuned-sst-2-english")

# –ó–∞–≥—Ä—É–∑–∏—Ç—å zero-shot model
zero_shot = pipeline("zero-shot-classification",
                     model="facebook/bart-large-mnli")
```

---

## ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

### –¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤–æ–π —Ä–∞–±–æ—Ç—ã

```bash
cd /core/sync
python ai_parser_transformer.py
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏):**

```
üß† –ó–∞–≥—Ä—É–∑–∫–∞ transformer –º–æ–¥–µ–ª–∏: distilbert-base-uncased-finetuned-sst-2-english
‚úÖ Zero-shot classification –∑–∞–≥—Ä—É–∂–µ–Ω
‚úÖ Transformer –º–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤—ã (GPU: ‚ùå)

üìä Model Info:
   Transformer Ready: ‚úÖ
   Model: distilbert-base-uncased-finetuned-sst-2-english
   Type: transformer-ml
```

**–ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã:**

```
‚ö†Ô∏è  transformers not installed, using mock fallback
üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ mock parser
Type: mock-fallback
```

### –¢–µ—Å—Ç 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∏—Å—å–º–∞

```python
from ai_parser_transformer import AIParserTransformer

parser = AIParserTransformer()

# –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
info = parser.get_model_info()
print(f"Transformer Ready: {info['transformer_ready']}")
print(f"Type: {info['type']}")

# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∏—Å—å–º–æ
result = parser.analyze_email(
    subject="Great work!",
    body="Thank you for the excellent job!"
)

print(f"Sentiment: {result['sentiment']}")
print(f"Score: {result['sentiment_score']:.2f}")
```

---

## üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from ai_parser_transformer import AIParserTransformer

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç –º–æ–¥–µ–ª–∏)
parser = AIParserTransformer()

# –ê–Ω–∞–ª–∏–∑ –ø–∏—Å—å–º–∞
meta = parser.analyze_email(
    subject="Urgent: Bug in production",
    body="We have a critical issue..."
)

print(f"Priority: {meta['priority']}")      # high
print(f"Category: {meta['category']}")      # Work
print(f"Sentiment: {meta['sentiment']}")    # negative
```

### –° GPU (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)

```python
# –í–∫–ª—é—á–∏—Ç—å GPU
parser = AIParserTransformer(use_gpu=True)

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ GPU
info = parser.get_model_info()
print(f"GPU Enabled: {info['gpu_enabled']}")
```

### –ü–∞–∫–µ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑

```python
emails = [
    {'subject': 'Meeting tomorrow', 'body_preview': '...'},
    {'subject': 'Invoice #123', 'body_preview': '...'}
]

# –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ø–∏—Å–µ–º
results = parser.batch_analyze(emails)

for result in results:
    print(f"{result['subject']}: {result['category']}")
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å SolarSync

```python
from solar_sync import SolarSync
from ai_parser_transformer import AIParserTransformer

# –°–æ–∑–¥–∞–µ–º sync —Å transformer parser
sync = SolarSync()
sync.ai_parser = AIParserTransformer()
sync.enable_ai = True

# –ó–∞–ø—É—Å–∫–∞–µ–º —É–º–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é —Å ML-–∞–Ω–∞–ª–∏–∑–æ–º
sync.smart_sync()
```

---

## üîç –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ü—Ä–æ–±–ª–µ–º–∞: ModuleNotFoundError: No module named 'transformers'

**–†–µ—à–µ–Ω–∏–µ:**
```bash
pip install transformers torch sentencepiece --break-system-packages
```

### –ü—Ä–æ–±–ª–µ–º–∞: "CUDA out of memory"

**–†–µ—à–µ–Ω–∏–µ 1:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ CPU mode
```python
parser = AIParserTransformer(use_gpu=False)
```

**–†–µ—à–µ–Ω–∏–µ 2:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å
```python
parser = AIParserTransformer(
    model_name="distilbert-base-uncased"  # –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏
)
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π

**–ü—Ä–∏—á–∏–Ω–∞:** –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ

**–†–µ—à–µ–Ω–∏–µ:** –î–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏. –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—É—Å–∫–∏ –±—É–¥—É—Ç –±—ã—Å—Ç—Ä—ã–º–∏ (–º–æ–¥–µ–ª–∏ –∫—ç—à–∏—Ä—É—é—Ç—Å—è).

**–ì–¥–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –º–æ–¥–µ–ª–∏:**
- Linux/Mac: `~/.cache/huggingface/`
- Windows: `C:\Users\<username>\.cache\huggingface\`

### –ü—Ä–æ–±–ª–µ–º–∞: ImportError: cannot import name 'pipeline'

**–†–µ—à–µ–Ω–∏–µ:** –û–±–Ω–æ–≤–∏—Ç–µ transformers
```bash
pip install --upgrade transformers --break-system-packages
```

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

| –†–µ–∂–∏–º | –°–∫–æ—Ä–æ—Å—Ç—å (–º—Å/–ø–∏—Å—å–º–æ) | –¢–æ—á–Ω–æ—Å—Ç—å | –ü–∞–º—è—Ç—å |
|-------|---------------------|----------|---------|
| Mock (Sprint 0.2) | 0-2 ms | 60-75% | ~5 MB |
| Transformer CPU | 50-200 ms | 85-95% | ~2 GB |
| Transformer GPU | 10-50 ms | 85-95% | ~3 GB VRAM |

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏

### Sentiment Analysis
- `distilbert-base-uncased-finetuned-sst-2-english` ‚úÖ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- `cardiffnlp/twitter-roberta-base-sentiment`
- `nlptown/bert-base-multilingual-uncased-sentiment`

### Zero-shot Classification
- `facebook/bart-large-mnli` ‚úÖ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- `joeddav/xlm-roberta-large-xnli`
- `MoritzLaurer/mDeBERTa-v3-base-mnli-xnli`

---

## üîú –ë—É–¥—É—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è (Sprint 0.4+)

- Fine-tuning –Ω–∞ email –∫–æ—Ä–ø—É—Å–∞—Ö
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
- NER (Named Entity Recognition) –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π
- Custom –º–æ–¥–µ–ª–∏ –¥–ª—è email-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á
- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Hugging Face Documentation](https://huggingface.co/docs/transformers)
- [PyTorch Installation Guide](https://pytorch.org/get-started/locally/)
- [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads)

---

**–°–æ–∑–¥–∞–Ω–æ –∫–æ–º–∞–Ω–¥–æ–π SolarMail** üåû
Sprint 0.3: AI Transformers Integration
